{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"../data/data_investeringer.xlsx\"\n",
    "data_path = \"../data/investeringer_datagrundlag.xlsx\"\n",
    "df = pd.read_excel(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the rows where \"Kommune\" is missing\n",
    "missing_kommune_rows = df[df['Kommune'].isna()]\n",
    "\n",
    "# Display the rows\n",
    "print(missing_kommune_rows)\n",
    "\n",
    "df = df[df['Kommune'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/full_data.xlsx\"\n",
    "full_data = pd.read_excel(data_path)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'Kommune' and check if there are any rows with a value in 'Priority'\n",
    "grouped = full_data.groupby('Kommune')['Priority'].apply(lambda x: x.notna().any() and x.isin([1, 2, 3]).any())\n",
    "\n",
    "# List of municipalities with at least one row with a priority value of 1, 2, or 3\n",
    "municipalities_with_priority = grouped[grouped == True].index.tolist()\n",
    "\n",
    "# List of municipalities with no rows having priority values\n",
    "municipalities_without_priority = grouped[grouped == False].index.tolist()\n",
    "\n",
    "# Display the results\n",
    "print(\"Municipalities with at least one row with Priority (1, 2, or 3):\")\n",
    "print(municipalities_with_priority)\n",
    "\n",
    "print(\"\\nMunicipalities with no Priority values (1, 2, or 3):\")\n",
    "print(municipalities_without_priority)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the lists are completely different\n",
    "intersection = set(municipalities_with_priority).intersection(municipalities_without_priority)\n",
    "\n",
    "# Display the lists and check for overlap\n",
    "if not intersection:\n",
    "    print(\"The lists are completely distinct.\")\n",
    "else:\n",
    "    print(\"The following municipalities appear in both lists:\")\n",
    "    print(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(full_data['Markedsværdi (DKK)']))\n",
    "print(sum(df['Markedsværdi (DKK)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace '-' with NaN (Fjerner dem, hvor der ikke er værdi. Det er fx to fra Odense)\n",
    "df['Markedsværdi (DKK)'] = df['Markedsværdi (DKK)'].replace('-', np.nan)\n",
    "\n",
    "# Remove any potential commas, spaces, or other non-numeric characters\n",
    "df['Markedsværdi (DKK)'] = df['Markedsværdi (DKK)'].replace({',': '', ' ': ''}, regex=True)\n",
    "\n",
    "# Convert the column to float\n",
    "df['Markedsværdi (DKK)'] = df['Markedsværdi (DKK)'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the function to fill missing 'Type' based on the majority for each 'ISIN kode'\n",
    "def fill_missing_type(df, min_rows=5, agree_threshold=0.8):\n",
    "    def fill_type_for_group(group):\n",
    "        # Count the missing values in 'Type' for this group\n",
    "        missing_count = group['Type'].isna().sum()\n",
    "        #print(f\"ISIN kode: {group.name}, Missing 'Type' values: {missing_count}\")\n",
    "        \n",
    "        # Get the count of each type in the group, excluding missing values\n",
    "        type_counts = group['Type'].value_counts()\n",
    "        \n",
    "        # If there are no valid types in the group, skip this group\n",
    "        if type_counts.empty:\n",
    "            return group\n",
    "        \n",
    "        total_rows = len(group)\n",
    "        most_common_type, most_common_count = type_counts.idxmax(), type_counts.max()\n",
    "        \n",
    "        # Check the condition: at least min_rows, and agreement should meet the threshold\n",
    "        if total_rows >= min_rows and most_common_count / total_rows >= agree_threshold:\n",
    "            # If conditions met, fill missing 'Type' with the most common type\n",
    "            group['Type'] = group['Type'].fillna(most_common_type)\n",
    "        \n",
    "        return group\n",
    "\n",
    "    # Group by 'ISIN kode' and apply the function to each group\n",
    "    df = df.groupby('ISIN kode').apply(fill_type_for_group)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Print the number of missing values in 'Type' before applying the function\n",
    "missing_before = df['Type'].isna().sum()\n",
    "print(f\"Missing 'Type' values before: {missing_before}\")\n",
    "\n",
    "# Apply the function to fill missing 'Type' values\n",
    "filled_df = fill_missing_type(df, min_rows=5, agree_threshold=0.80)\n",
    "\n",
    "# Print the number of missing values in 'Type' after applying the function\n",
    "missing_after = filled_df['Type'].isna().sum()\n",
    "print(f\"Missing 'Type' values after: {missing_after}\")\n",
    "\n",
    "filled_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lav = df[df['Markedsværdi (DKK)'] < 100]\n",
    "df_lav = df_lav[df_lav['Markedsværdi (DKK)'] >= 0]\n",
    "df_lav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_lav['Markedsværdi (DKK)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('Kommune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[df['Kommune'] == 'Guldborgsund'].to_string(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "# Function to convert dataframe to text and count tokens\n",
    "def dataframe_to_text(df):\n",
    "    \"\"\"\n",
    "    This function converts a dataframe into a text format.\n",
    "    You can modify it based on how you want to present the data.\n",
    "    \"\"\"\n",
    "    text = df.to_string(index=False)  # Convert DataFrame to string (or JSON if needed)\n",
    "    return text\n",
    "\n",
    "# Function to count tokens using OpenAI's tokenizer (tiktoken)\n",
    "def count_tokens(text, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    Counts the number of tokens in a given text based on the OpenAI model.\n",
    "    \"\"\"\n",
    "    # Load the encoding for the specified model (gpt-3.5-turbo, gpt-4, etc.)\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    \n",
    "    # Encode the text into tokens\n",
    "    tokens = encoding.encode(text)\n",
    "    \n",
    "    # Return the number of tokens\n",
    "    return len(tokens)\n",
    "\n",
    "# Convert dataframe to text\n",
    "df_text = dataframe_to_text(df['Markedsværdi (DKK)'][df['Kommune'] == 'Guldborgsund'])\n",
    "\n",
    "# Count tokens\n",
    "num_tokens = count_tokens(df_text, model=\"gpt-4\")\n",
    "\n",
    "# print(f\"DataFrame text:\\n{df_text}\")\n",
    "print(f\"\\nNumber of tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danwatch-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/datagrundlag_FN.xlsx\"\n",
    "df = pd.read_excel(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fn = df[df['Problematisk ifølge:'] == 'FN']\n",
    "sum(round(df_fn['Markedsværdi (DKK)'],5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decrypted DataFrame:\n",
      "     Kommune     ISIN kode              Værdipapirets navn  \\\n",
      "0    Rødovre  AEA000801018     Abu Dhabi Islamic Bank PJSC   \n",
      "1  Holstebro  AEA002001013                Aldar Properties   \n",
      "2       Fanø  AEA002001013           Aldar Properties PJSC   \n",
      "3       Fanø  AEE000301011           Emaar Properties PJSC   \n",
      "4       Fanø  AEE000401019  Emirates Telecommunications Gr   \n",
      "\n",
      "                      Udsteder  Markedsværdi (DKK)   Type  \\\n",
      "0  Abu Dhabi Islamic Bank PJSC         4420.591824  Aktie   \n",
      "1             Aldar Properties        48912.517111  Aktie   \n",
      "2         United Arab Emirates           56.605770  Aktie   \n",
      "3         United Arab Emirates          396.240390  Aktie   \n",
      "4         United Arab Emirates          396.240390  Aktie   \n",
      "\n",
      "  Årsag til eksklusion OBS_Type  Priority Problematisk ifølge:  Sortlistet  \\\n",
      "0                 None     None       NaN                 None           0   \n",
      "1                 None     None       NaN                 None           0   \n",
      "2                 None     None       NaN                 None           0   \n",
      "3                 None     None       NaN                 None           0   \n",
      "4                 None     None       NaN                 None           0   \n",
      "\n",
      "  Eksklusionsårsager Problemkategori  \n",
      "0               None            None  \n",
      "1               None            None  \n",
      "2               None            None  \n",
      "3               None            None  \n",
      "4               None            None  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os \n",
    "import base64\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.hazmat.primitives import padding\n",
    "\n",
    "\n",
    "# Decrypt data using AES-CBC mode\n",
    "def aes_decrypt(encrypted_data, key):\n",
    "    encrypted_data = base64.b64decode(encrypted_data.encode())  # Decode Base64 to bytes\n",
    "    iv = encrypted_data[:16]  # Extract the first 16 bytes as the IV\n",
    "    ciphertext = encrypted_data[16:]\n",
    "\n",
    "    cipher = Cipher(algorithms.AES(key), modes.CBC(iv), backend=default_backend())\n",
    "    decryptor = cipher.decryptor()\n",
    "\n",
    "    decrypted_padded_data = decryptor.update(ciphertext) + decryptor.finalize()\n",
    "\n",
    "    # Remove padding\n",
    "    unpadder = padding.PKCS7(128).unpadder()\n",
    "    decrypted_data = unpadder.update(decrypted_padded_data) + unpadder.finalize()\n",
    "\n",
    "    return decrypted_data.decode()\n",
    "\n",
    "# Function to decrypt specified columns of the DataFrame using AES-CBC\n",
    "def decrypt_dataframe(df, key, col_list):\n",
    "    df_decrypted = df.copy()  # Create a copy of the DataFrame\n",
    "\n",
    "    for col in col_list:\n",
    "        if pd.api.types.is_string_dtype(df_decrypted[col]):\n",
    "            # Decrypt string columns\n",
    "            df_decrypted[col] = df_decrypted[col].apply(lambda x: aes_decrypt(x, key))\n",
    "        else:\n",
    "            # Convert to the original data type after decryption\n",
    "            df_decrypted[col] = df_decrypted[col].apply(lambda x: aes_decrypt(str(x), key))\n",
    "\n",
    "    return df_decrypted\n",
    "\n",
    "# Only encrypt the necessary columns\n",
    "col_list = [\"Kommune\", \"ISIN kode\", \"Værdipapirets navn\"]\n",
    "\n",
    "# Fetch the base64 encoded key from environment variables\n",
    "encoded_key = os.getenv(\"ENCRYPTION_KEY\")\n",
    "\n",
    "# Decode the key back to bytes for AES use\n",
    "encryption_key = base64.b64decode(encoded_key)\n",
    "\n",
    "\n",
    "# Create an SQLite engine\n",
    "engine = create_engine(\"sqlite:///../src/investerings_database_encrypted_new.db\")\n",
    "\n",
    "# --- Optional: Decrypt the DataFrame for verification ---\n",
    "df_retrieved = pd.read_sql(\"SELECT * FROM kommunale_regioner_investeringer\", engine)\n",
    "df_decrypted = decrypt_dataframe(df_retrieved, encryption_key, col_list)\n",
    "print(\"Decrypted DataFrame:\")\n",
    "print(df_decrypted.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter for rows where 'Priority' is 2 or 3\n",
    "priority_2_or_3_df = df_decrypted[df_decrypted['Priority'].isin([2, 3])]\n",
    "\n",
    "# Step 2: Get unique 'Kommune' values where 'Priority' is 2 or 3\n",
    "kommuner_with_priority_2_or_3 = priority_2_or_3_df['Kommune'].unique()\n",
    "\n",
    "# Step 3: Get all unique 'Kommune' values in the DataFrame\n",
    "all_kommuner = df_decrypted['Kommune'].unique()\n",
    "\n",
    "# Step 4: Find 'Kommune' values that don't have any 'Priority' of 2 or 3\n",
    "kommuner_without_priority_2_or_3 = list(set(all_kommuner) - set(kommuner_with_priority_2_or_3))\n",
    "\n",
    "# Print the results\n",
    "print(\"Kommunes with Priority 2 or 3:\", kommuner_with_priority_2_or_3)\n",
    "print(\"Kommunes without Priority 2 or 3:\", kommuner_without_priority_2_or_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decrypted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_decrypted is your existing dataframe\n",
    "# Step 1: Split the 'Problemkategori' column by ';' and expand them into separate rows\n",
    "df_expanded = df_decrypted.assign(\n",
    "    Problemkategori=df_decrypted['Problemkategori'].str.split(';')\n",
    ").explode('Problemkategori')\n",
    "\n",
    "# Step 2: Strip any extra spaces in 'Problemkategori'\n",
    "df_expanded['Problemkategori'] = df_expanded['Problemkategori'].str.strip()\n",
    "\n",
    "# Step 3: Grouping by 'Kommune' and 'Problemkategori', and aggregating\n",
    "df_grouped = df_expanded.groupby(['Kommune', 'Problemkategori']).agg(\n",
    "    Antal=('Problemkategori', 'size'),  # Counting occurrences\n",
    "    Markedsværdi_sum=('Markedsværdi (DKK)', 'sum')  # Summing the values\n",
    ").reset_index()\n",
    "\n",
    "# Step 4: Rounding the 'Markedsværdi_sum' to 2 decimal places\n",
    "df_grouped['Markedsværdi_sum'] = df_grouped['Markedsværdi_sum'].round(2)\n",
    "\n",
    "\n",
    "# Saving the result to a CSV file\n",
    "df_grouped.to_csv('investeringer_problemkategori.csv', index=False)\n",
    "\n",
    "print(df_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 0: Filter the dataframe to keep only rows where 'Priority' is 2 or 3\n",
    "df_filtered = df_decrypted[df_decrypted['Priority'].isin([2, 3])]\n",
    "\n",
    "# Step 1: Split the 'Problemkategori' column by ';' and expand them into separate rows\n",
    "df_expanded = df_filtered.assign(\n",
    "    Problemkategori=df_filtered['Problemkategori'].str.split(';')\n",
    ").explode('Problemkategori')\n",
    "\n",
    "# Step 2: Strip any extra spaces in 'Problemkategori'\n",
    "df_expanded['Problemkategori'] = df_expanded['Problemkategori'].str.strip()\n",
    "\n",
    "# Step 3: Create a crosstab for 'Kommune' and 'Problemkategori'\n",
    "df_crosstab = pd.crosstab(df_expanded['Kommune'], df_expanded['Problemkategori'])\n",
    "\n",
    "# Step 4: Adding a 'Total' column that sums up all non-empty 'Problemkategori' counts\n",
    "df_crosstab['Total'] = df_crosstab.sum(axis=1)\n",
    "\n",
    "# Step 5: Get the total 'Markedsværdi (DKK)' sum for each 'Kommune' from the original df_decrypted\n",
    "df_markedsværdi_sum = df_filtered.groupby('Kommune')['Markedsværdi (DKK)'].sum().reset_index()\n",
    "\n",
    "df_result = df_crosstab.merge(df_markedsværdi_sum, on='Kommune')\n",
    "\n",
    "df_result['Markedsværdi (DKK)'] = df_result['Markedsværdi (DKK)'].round(2)\n",
    "\n",
    "# Step 6: Saving the result to a CSV file\n",
    "df_result.to_csv('investeringer_problemkategori_kolonner.csv', index=False)\n",
    "\n",
    "print(df_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company name</th>\n",
       "      <th>ISIN</th>\n",
       "      <th>HQ Country</th>\n",
       "      <th>HQ Region</th>\n",
       "      <th>Sector cluster</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Scope 3 cat</th>\n",
       "      <th>1.1 metric assessment</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Indicator 1 assessment</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 72</th>\n",
       "      <th>Indicator 9</th>\n",
       "      <th>Unnamed: 74</th>\n",
       "      <th>10.1</th>\n",
       "      <th>Unnamed: 76</th>\n",
       "      <th>Sub indicator 10.1 assessment</th>\n",
       "      <th>10.2</th>\n",
       "      <th>Unnamed: 79</th>\n",
       "      <th>Sub indicator 10.2 assessment</th>\n",
       "      <th>Indicator 10 assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.P. Moller (Maersk)</td>\n",
       "      <td>DK0010244425</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>Shipping</td>\n",
       "      <td>No</td>\n",
       "      <td>Y</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not assessed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelaide Brighton</td>\n",
       "      <td>AU000000ABC7</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Cement</td>\n",
       "      <td>No</td>\n",
       "      <td>N</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not assessed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AES Corp.</td>\n",
       "      <td>US00130H1059</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Electricity Utilities</td>\n",
       "      <td>No</td>\n",
       "      <td>Y</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not assessed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGL Energy Ltd.</td>\n",
       "      <td>AU000000AGL7</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Electricity Utilities</td>\n",
       "      <td>Yes (use of sold product from oil and gas dist...</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Partial</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not assessed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air France-KLM</td>\n",
       "      <td>FR0000031122</td>\n",
       "      <td>France</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>No</td>\n",
       "      <td>N</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not assessed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Company name          ISIN HQ Country      HQ Region  \\\n",
       "0  A.P. Moller (Maersk)  DK0010244425    Denmark         Europe   \n",
       "1     Adelaide Brighton  AU000000ABC7  Australia        Oceania   \n",
       "2             AES Corp.  US00130H1059        USA  North America   \n",
       "3       AGL Energy Ltd.  AU000000AGL7  Australia        Oceania   \n",
       "4        Air France-KLM  FR0000031122     France         Europe   \n",
       "\n",
       "   Sector cluster                 Sector  \\\n",
       "0  Transportation               Shipping   \n",
       "1     Industrials                 Cement   \n",
       "2          Energy  Electricity Utilities   \n",
       "3          Energy  Electricity Utilities   \n",
       "4  Transportation               Airlines   \n",
       "\n",
       "                                         Scope 3 cat 1.1 metric assessment  \\\n",
       "0                                                 No                     Y   \n",
       "1                                                 No                     N   \n",
       "2                                                 No                     Y   \n",
       "3  Yes (use of sold product from oil and gas dist...                     Y   \n",
       "4                                                 No                     N   \n",
       "\n",
       "       Unnamed: 8 Indicator 1 assessment  ...  Unnamed: 72   Indicator 9  \\\n",
       "0  Not applicable                      Y  ...          NaN  Not assessed   \n",
       "1  Not applicable                      N  ...          NaN  Not assessed   \n",
       "2  Not applicable                      Y  ...          NaN  Not assessed   \n",
       "3               N                Partial  ...          NaN  Not assessed   \n",
       "4  Not applicable                      N  ...          NaN  Not assessed   \n",
       "\n",
       "  Unnamed: 74 10.1 Unnamed: 76 Sub indicator 10.1 assessment 10.2 Unnamed: 79  \\\n",
       "0         NaN    Y           Y                             Y    Y           N   \n",
       "1         NaN    Y           Y                             Y    Y           N   \n",
       "2         NaN    Y           N                       Partial    Y           Y   \n",
       "3         NaN    Y           Y                             Y    Y           Y   \n",
       "4         NaN    Y           Y                             Y    N           N   \n",
       "\n",
       "   Sub indicator 10.2 assessment Indicator 10 assessment  \n",
       "0                        Partial                 Partial  \n",
       "1                        Partial                 Partial  \n",
       "2                              Y                 Partial  \n",
       "3                              Y                       Y  \n",
       "4                              N                 Partial  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Match med klima \n",
    "\n",
    "clima_list = df = pd.read_excel(\"../data/Climate-Action-100-Company-Assessments-Version-1.5.xlsx\", sheet_name=\"Disclosure Assessments\", header=8, skiprows=[9])\n",
    "clima_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes based on matching 'ISIN' from clima_list and 'ISIN kode' from decrypted_df\n",
    "merged_df = pd.merge(df_decrypted, clima_list, left_on='ISIN kode', right_on='ISIN', how='inner')\n",
    "merged_df.to_csv(\"samlet-data-sammenkørsel-med-Climate-Action-100-Company-Assessments.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Kommune  Markedsværdi_sum  Antal\n",
      "0         Aabenraa        2896918.49    103\n",
      "1          Aalborg        1697791.76     58\n",
      "2           Aarhus       31796829.00     40\n",
      "3           Assens        7154348.80    100\n",
      "4         Ballerup        1552914.81     38\n",
      "..             ...               ...    ...\n",
      "72      Vallensbæk        1063143.38     62\n",
      "73           Varde        4496635.46     60\n",
      "74           Vejle          77989.47      4\n",
      "75  Vesthimmerland        2321333.70      5\n",
      "76          Viborg        6190912.22     77\n",
      "\n",
      "[77 rows x 3 columns]\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Kommune' to get the sum of 'Markedsværdi (DKK)' and the count of rows\n",
    "grouped_df = merged_df.groupby('Kommune').agg(\n",
    "    Markedsværdi_sum=('Markedsværdi (DKK)', 'sum'),  # Sum of 'Markedsværdi (DKK)'\n",
    "    Antal=('Kommune', 'size')  # Count of rows (Antal) for each 'Kommune'\n",
    ").reset_index()\n",
    "\n",
    "grouped_df['Markedsværdi_sum'] = round(grouped_df['Markedsværdi_sum'], 2)\n",
    "# Display the new dataframe\n",
    "print(grouped_df)\n",
    "grouped_df.to_csv('sammenkørsel-med-Climate-Action-100-Company-Assessments.csv')\n",
    "\n",
    "print(len(grouped_df['Kommune'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
